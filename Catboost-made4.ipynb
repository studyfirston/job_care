{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- depth + bagging_temperature + 더 깊게 학습하게 만들기.\n",
    "- 해볼 것\n",
    "-> bagging_temperature 이란?\n",
    "-> 더 깊게 학습하는 방법은?\n",
    "-> overtfittign 을 막을 수 있는 방법은?\n",
    "\n",
    "---\n",
    "- model 5개의 평균을 만들어서 평가하고 있는데, 그 중 가장 좋은 model로 값을 뽑아내면 좋지 않을까?\n",
    "\n",
    "- threshold 를 for 문 구간을 통해서 구하게 변경\n",
    "\n",
    "- 산술평균 앙상블 대신에, threshold 값을 기준으로 하드보팅 앙상블 방법으로 진행해보는 것은 어떨까?\n",
    "-> threshold 인 pred_proba가 0.4 이상인 값이 3개 이상이라면 True 같은 느낌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "SUBMIT_PATH = \"submit/\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import random\n",
    "import math\n",
    "from typing import List ,Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "import sklearn \n",
    "from sklearn.model_selection import StratifiedKFold , KFold\n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "from catboost import Pool,CatBoostClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 35), (46404, 34))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(f'{DATA_PATH}train.csv')\n",
    "test_data = pd.read_csv(f'{DATA_PATH}test.csv')\n",
    "\n",
    "\n",
    "train_data.shape , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_l_match_yn</th>\n",
       "      <th>d_m_match_yn</th>\n",
       "      <th>d_s_match_yn</th>\n",
       "      <th>h_l_match_yn</th>\n",
       "      <th>h_m_match_yn</th>\n",
       "      <th>h_s_match_yn</th>\n",
       "      <th>person_attribute_a</th>\n",
       "      <th>person_attribute_a_1</th>\n",
       "      <th>person_attribute_b</th>\n",
       "      <th>...</th>\n",
       "      <th>contents_attribute_l</th>\n",
       "      <th>contents_attribute_d</th>\n",
       "      <th>contents_attribute_m</th>\n",
       "      <th>contents_attribute_e</th>\n",
       "      <th>contents_attribute_h</th>\n",
       "      <th>person_rn</th>\n",
       "      <th>contents_rn</th>\n",
       "      <th>contents_open_dt</th>\n",
       "      <th>target</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>618822</td>\n",
       "      <td>354805</td>\n",
       "      <td>2020-01-17 12:09:36</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>571659</td>\n",
       "      <td>346213</td>\n",
       "      <td>2020-06-18 17:48:52</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1600</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>399816</td>\n",
       "      <td>206408</td>\n",
       "      <td>2020-07-08 20:00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  d_l_match_yn  d_m_match_yn  d_s_match_yn  h_l_match_yn  h_m_match_yn  \\\n",
       "0   0          True          True          True         False         False   \n",
       "1   1         False         False         False          True          True   \n",
       "2   2         False         False         False          True         False   \n",
       "\n",
       "   h_s_match_yn  person_attribute_a  person_attribute_a_1  person_attribute_b  \\\n",
       "0         False                   1                     4                   3   \n",
       "1         False                   1                     3                   4   \n",
       "2         False                   2                     0                   3   \n",
       "\n",
       "   ...  contents_attribute_l  contents_attribute_d  contents_attribute_m  \\\n",
       "0  ...                  1608                   275                     1   \n",
       "1  ...                  1608                   275                     1   \n",
       "2  ...                  1600                    94                     1   \n",
       "\n",
       "   contents_attribute_e  contents_attribute_h  person_rn  contents_rn  \\\n",
       "0                     4                   139     618822       354805   \n",
       "1                     4                   133     571659       346213   \n",
       "2                     4                    53     399816       206408   \n",
       "\n",
       "     contents_open_dt  target  hour  \n",
       "0 2020-01-17 12:09:36       1    12  \n",
       "1 2020-06-18 17:48:52       0    17  \n",
       "2 2020-07-08 20:00:10       0    20  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hour 변수를 넣기 위해서 추가\n",
    "train_data['contents_open_dt'] = train_data['contents_open_dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "test_data['contents_open_dt'] = test_data['contents_open_dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "train_data['hour'] = train_data['contents_open_dt'].apply(lambda x : x.timetuple()[3])\n",
    "test_data['hour'] = test_data['contents_open_dt'].apply(lambda x : x.timetuple()[3])\n",
    "\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data EDA에 따라서\n",
    "# good - mid - low time (target에 따라서 good <-> low 범위)\n",
    "# low : 23~07\n",
    "# mid : 17~22\n",
    "# good : 8~16\n",
    "train_data.loc[train_data['hour']<=7, 'hour_band'] = 'low_time'\n",
    "train_data.loc[train_data['hour']==23, 'hour_band'] = 'low_time'\n",
    "\n",
    "train_data.loc[(train_data['hour']>7) & (train_data['hour'] <= 16), 'hour_band'] = 'good_time'\n",
    "train_data.loc[(train_data['hour']>=17) & (train_data['hour']<=22), 'hour_band'] = 'mid_time'\n",
    "train_data = train_data.drop(columns = ['hour'])\n",
    "\n",
    "test_data.loc[test_data['hour']<=7, 'hour_band'] = 'low_time'\n",
    "test_data.loc[test_data['hour']==23, 'hour_band'] = 'low_time'\n",
    "\n",
    "test_data.loc[(test_data['hour']>7) & (test_data['hour'] <= 16), 'hour_band'] = 'good_time'\n",
    "test_data.loc[(test_data['hour']>=17) & (test_data['hour']<=22), 'hour_band'] = 'mid_time'\n",
    "test_data = test_data.drop(columns = ['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def add_code(\n",
    "    df: pd.DataFrame,\n",
    "    d_code: Dict[int, Dict[str, int]], \n",
    "    h_code: Dict[int, Dict[str, int]], \n",
    "    l_code: Dict[int, Dict[str, int]],\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # Copy input data\n",
    "    df = df.copy()   \n",
    "\n",
    "    # D Code\n",
    "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    # H Code\n",
    "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    \n",
    "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    \n",
    "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "\n",
    "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "\n",
    "    # L Code\n",
    "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
    "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
    "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
    "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_code = pd.read_csv('data/속성_D_코드.csv', index_col=0).T.to_dict()\n",
    "h_code = pd.read_csv('data/속성_H_코드.csv', index_col=0).T.to_dict()\n",
    "l_code = pd.read_csv('data/속성_L_코드.csv', index_col=0).T.to_dict()\n",
    "\n",
    "\n",
    "train_data = add_code(train_data, d_code, h_code, l_code)\n",
    "test_data = add_code(test_data, d_code, h_code, l_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'd_l_match_yn', 'd_m_match_yn', 'd_s_match_yn', 'h_l_match_yn',\n",
       "       'h_m_match_yn', 'h_s_match_yn', 'person_attribute_a',\n",
       "       'person_attribute_a_1', 'person_attribute_b', 'person_prefer_c',\n",
       "       'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
       "       'person_prefer_e', 'person_prefer_f', 'person_prefer_g',\n",
       "       'person_prefer_h_1', 'person_prefer_h_2', 'person_prefer_h_3',\n",
       "       'contents_attribute_i', 'contents_attribute_a',\n",
       "       'contents_attribute_j_1', 'contents_attribute_j',\n",
       "       'contents_attribute_c', 'contents_attribute_k', 'contents_attribute_l',\n",
       "       'contents_attribute_d', 'contents_attribute_m', 'contents_attribute_e',\n",
       "       'contents_attribute_h', 'person_rn', 'contents_rn', 'contents_open_dt',\n",
       "       'target', 'hour_band', 'person_prefer_d_1_n', 'person_prefer_d_1_s',\n",
       "       'person_prefer_d_1_m', 'person_prefer_d_1_l', 'person_prefer_d_2_n',\n",
       "       'person_prefer_d_2_s', 'person_prefer_d_2_m', 'person_prefer_d_2_l',\n",
       "       'person_prefer_d_3_n', 'person_prefer_d_3_s', 'person_prefer_d_3_m',\n",
       "       'person_prefer_d_3_l', 'contents_attribute_d_n',\n",
       "       'contents_attribute_d_s', 'contents_attribute_d_m',\n",
       "       'contents_attribute_d_l', 'person_prefer_h_1_l', 'person_prefer_h_1_m',\n",
       "       'person_prefer_h_2_l', 'person_prefer_h_2_m', 'person_prefer_h_3_l',\n",
       "       'person_prefer_h_3_m', 'contents_attribute_h_l',\n",
       "       'contents_attribute_h_m', 'contents_attribute_l_n',\n",
       "       'contents_attribute_l_s', 'contents_attribute_l_m',\n",
       "       'contents_attribute_l_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = [\"id\",\"person_prefer_f\",\"person_prefer_g\" ,\"contents_open_dt\", \"contents_rn\", ]\n",
    "\n",
    "train_data = train_data.drop(columns = cols_drop)\n",
    "test_data = test_data.drop(columns = cols_drop)\n",
    "\n",
    "\n",
    "# x_train, y_train = preprocess_data(train_data, cols_merge = cols_merge , cols_equi= cols_equi , cols_drop = cols_drop)\n",
    "# x_test, _ = preprocess_data(test_data,is_train = False, cols_merge = cols_merge , cols_equi= cols_equi  , cols_drop = cols_drop)\n",
    "# x_train.shape , y_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분을 추가한 모델이 성능이 조금은 더 높더라.\n",
    "# 변수 개수가 여기에서 차이가 난다.\n",
    "cols_equi = [\n",
    "\n",
    "    (\"contents_attribute_c\",\"person_prefer_c\"),\n",
    "    (\"contents_attribute_e\",\"person_prefer_e\"),\n",
    "\n",
    "    (\"person_prefer_d_2_s\" , \"contents_attribute_d_s\"),\n",
    "    (\"person_prefer_d_2_m\" , \"contents_attribute_d_m\"),\n",
    "    (\"person_prefer_d_2_l\" , \"contents_attribute_d_l\"),\n",
    "    (\"person_prefer_d_3_s\" , \"contents_attribute_d_s\"),\n",
    "    (\"person_prefer_d_3_m\" , \"contents_attribute_d_m\"),\n",
    "    (\"person_prefer_d_3_l\" , \"contents_attribute_d_l\"),\n",
    "\n",
    "    (\"person_prefer_h_1_m\" , \"contents_attribute_h_m\"),\n",
    "    (\"person_prefer_h_2_m\" , \"contents_attribute_h_m\"),\n",
    "    (\"person_prefer_h_3_m\" , \"contents_attribute_h_m\"),\n",
    "    (\"person_prefer_h_1_l\" , \"contents_attribute_h_l\"),\n",
    "    (\"person_prefer_h_2_l\" , \"contents_attribute_h_l\"),\n",
    "    (\"person_prefer_h_3_l\" , \"contents_attribute_h_l\"),\n",
    "]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = ['d_l_match_yn',\t'd_m_match_yn',\t'd_s_match_yn'\t,'h_l_match_yn','h_m_match_yn',\t'h_s_match_yn',\t'person_attribute_a']\n",
    "def preprocess_data(\n",
    "                    df:pd.DataFrame,\n",
    "                    cols_equi:List[Tuple[str,str]]= [] )->Tuple[pd.DataFrame,np.ndarray]:\n",
    "    df = df.copy()\n",
    "\n",
    "\n",
    "    cols = df.select_dtypes(bool).columns.tolist()\n",
    "    df[cols] = df[cols].astype(int)\n",
    "\n",
    "    for col1, col2 in cols_equi:\n",
    "        df[f\"{col1}_{col2}\"] = (df[col1] == df[col2] ).astype(int)\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d_l_match_yn', 'd_m_match_yn', 'd_s_match_yn', 'h_l_match_yn',\n",
       "       'h_m_match_yn', 'h_s_match_yn', 'person_attribute_a',\n",
       "       'person_attribute_a_1', 'person_attribute_b', 'person_prefer_c',\n",
       "       'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
       "       'person_prefer_e', 'person_prefer_h_1', 'person_prefer_h_2',\n",
       "       'person_prefer_h_3', 'contents_attribute_i', 'contents_attribute_a',\n",
       "       'contents_attribute_j_1', 'contents_attribute_j',\n",
       "       'contents_attribute_c', 'contents_attribute_k', 'contents_attribute_l',\n",
       "       'contents_attribute_d', 'contents_attribute_m', 'contents_attribute_e',\n",
       "       'contents_attribute_h', 'person_rn', 'target', 'hour_band',\n",
       "       'person_prefer_d_1_n', 'person_prefer_d_1_s', 'person_prefer_d_1_m',\n",
       "       'person_prefer_d_1_l', 'person_prefer_d_2_n', 'person_prefer_d_2_s',\n",
       "       'person_prefer_d_2_m', 'person_prefer_d_2_l', 'person_prefer_d_3_n',\n",
       "       'person_prefer_d_3_s', 'person_prefer_d_3_m', 'person_prefer_d_3_l',\n",
       "       'contents_attribute_d_n', 'contents_attribute_d_s',\n",
       "       'contents_attribute_d_m', 'contents_attribute_d_l',\n",
       "       'person_prefer_h_1_l', 'person_prefer_h_1_m', 'person_prefer_h_2_l',\n",
       "       'person_prefer_h_2_m', 'person_prefer_h_3_l', 'person_prefer_h_3_m',\n",
       "       'contents_attribute_h_l', 'contents_attribute_h_m',\n",
       "       'contents_attribute_l_n', 'contents_attribute_l_s',\n",
       "       'contents_attribute_l_m', 'contents_attribute_l_l',\n",
       "       'contents_attribute_c_person_prefer_c',\n",
       "       'contents_attribute_e_person_prefer_e',\n",
       "       'person_prefer_d_2_s_contents_attribute_d_s',\n",
       "       'person_prefer_d_2_m_contents_attribute_d_m',\n",
       "       'person_prefer_d_2_l_contents_attribute_d_l',\n",
       "       'person_prefer_d_3_s_contents_attribute_d_s',\n",
       "       'person_prefer_d_3_m_contents_attribute_d_m',\n",
       "       'person_prefer_d_3_l_contents_attribute_d_l',\n",
       "       'person_prefer_h_1_m_contents_attribute_h_m',\n",
       "       'person_prefer_h_2_m_contents_attribute_h_m',\n",
       "       'person_prefer_h_3_m_contents_attribute_h_m',\n",
       "       'person_prefer_h_1_l_contents_attribute_h_l',\n",
       "       'person_prefer_h_2_l_contents_attribute_h_l',\n",
       "       'person_prefer_h_3_l_contents_attribute_h_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data(train_data, cols_equi).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_data(train_data, cols_equi)\n",
    "test_data = preprocess_data(test_data, cols_equi)\n",
    "\n",
    "y_train = train_data.pop('target')\n",
    "x_train = train_data\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = x_train.columns[x_train.nunique() > 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person_attribute_a_1',\n",
       " 'person_attribute_b',\n",
       " 'person_prefer_c',\n",
       " 'person_prefer_d_1',\n",
       " 'person_prefer_d_2',\n",
       " 'person_prefer_d_3',\n",
       " 'person_prefer_e',\n",
       " 'person_prefer_h_1',\n",
       " 'person_prefer_h_2',\n",
       " 'person_prefer_h_3',\n",
       " 'contents_attribute_i',\n",
       " 'contents_attribute_a',\n",
       " 'contents_attribute_j_1',\n",
       " 'contents_attribute_c',\n",
       " 'contents_attribute_l',\n",
       " 'contents_attribute_d',\n",
       " 'contents_attribute_m',\n",
       " 'contents_attribute_e',\n",
       " 'contents_attribute_h',\n",
       " 'person_rn',\n",
       " 'hour_band',\n",
       " 'person_prefer_d_1_n',\n",
       " 'person_prefer_d_1_s',\n",
       " 'person_prefer_d_1_m',\n",
       " 'person_prefer_d_1_l',\n",
       " 'person_prefer_d_2_n',\n",
       " 'person_prefer_d_2_s',\n",
       " 'person_prefer_d_2_m',\n",
       " 'person_prefer_d_2_l',\n",
       " 'person_prefer_d_3_n',\n",
       " 'person_prefer_d_3_s',\n",
       " 'person_prefer_d_3_m',\n",
       " 'person_prefer_d_3_l',\n",
       " 'contents_attribute_d_n',\n",
       " 'contents_attribute_d_s',\n",
       " 'contents_attribute_d_m',\n",
       " 'contents_attribute_d_l',\n",
       " 'person_prefer_h_1_l',\n",
       " 'person_prefer_h_1_m',\n",
       " 'person_prefer_h_2_l',\n",
       " 'person_prefer_h_2_m',\n",
       " 'person_prefer_h_3_l',\n",
       " 'person_prefer_h_3_m',\n",
       " 'contents_attribute_h_l',\n",
       " 'contents_attribute_h_m',\n",
       " 'contents_attribute_l_n',\n",
       " 'contents_attribute_l_s',\n",
       " 'contents_attribute_l_m',\n",
       " 'contents_attribute_l_l']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "n_splits = 5 # 기존 5\n",
    "iterations = 10000 # 기존 3000\n",
    "patience = 200\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6208467\ttest: 0.6196185\tbest: 0.6196185 (0)\ttotal: 104ms\tremaining: 17m 19s\n",
      "100:\tlearn: 0.6514052\ttest: 0.6550750\tbest: 0.6550750 (100)\ttotal: 8.94s\tremaining: 14m 35s\n",
      "200:\tlearn: 0.6577890\ttest: 0.6607306\tbest: 0.6608856 (196)\ttotal: 17.8s\tremaining: 14m 28s\n",
      "300:\tlearn: 0.6662070\ttest: 0.6724514\tbest: 0.6724514 (300)\ttotal: 26.4s\tremaining: 14m 9s\n",
      "400:\tlearn: 0.6737380\ttest: 0.6790632\tbest: 0.6790632 (400)\ttotal: 34.8s\tremaining: 13m 53s\n",
      "500:\tlearn: 0.6794737\ttest: 0.6842533\tbest: 0.6842950 (499)\ttotal: 43.2s\tremaining: 13m 39s\n",
      "600:\tlearn: 0.6848177\ttest: 0.6863817\tbest: 0.6863817 (600)\ttotal: 51.6s\tremaining: 13m 26s\n",
      "700:\tlearn: 0.6898518\ttest: 0.6877063\tbest: 0.6877359 (693)\ttotal: 60s\tremaining: 13m 15s\n",
      "800:\tlearn: 0.6948310\ttest: 0.6885246\tbest: 0.6886186 (770)\ttotal: 1m 8s\tremaining: 13m 5s\n",
      "900:\tlearn: 0.6992347\ttest: 0.6884749\tbest: 0.6886186 (770)\ttotal: 1m 16s\tremaining: 12m 53s\n",
      "1000:\tlearn: 0.7034139\ttest: 0.6882876\tbest: 0.6886197 (924)\ttotal: 1m 24s\tremaining: 12m 43s\n",
      "1100:\tlearn: 0.7071869\ttest: 0.6882177\tbest: 0.6886197 (924)\ttotal: 1m 33s\tremaining: 12m 32s\n",
      "1200:\tlearn: 0.7106345\ttest: 0.6884967\tbest: 0.6886735 (1185)\ttotal: 1m 41s\tremaining: 12m 22s\n",
      "1300:\tlearn: 0.7139070\ttest: 0.6883357\tbest: 0.6886735 (1185)\ttotal: 1m 49s\tremaining: 12m 12s\n",
      "bestTest = 0.688673485\n",
      "bestIteration = 1185\n",
      "Shrink model to first 1186 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6185772\ttest: 0.6211568\tbest: 0.6211568 (0)\ttotal: 104ms\tremaining: 17m 23s\n",
      "100:\tlearn: 0.6503384\ttest: 0.6558264\tbest: 0.6558264 (100)\ttotal: 8.98s\tremaining: 14m 40s\n",
      "200:\tlearn: 0.6570170\ttest: 0.6624206\tbest: 0.6624206 (200)\ttotal: 17.9s\tremaining: 14m 32s\n",
      "300:\tlearn: 0.6647591\ttest: 0.6703989\tbest: 0.6704049 (299)\ttotal: 26.6s\tremaining: 14m 17s\n",
      "400:\tlearn: 0.6721103\ttest: 0.6789482\tbest: 0.6789849 (398)\ttotal: 35.1s\tremaining: 13m 59s\n",
      "500:\tlearn: 0.6783038\ttest: 0.6831809\tbest: 0.6832593 (499)\ttotal: 43.4s\tremaining: 13m 43s\n",
      "600:\tlearn: 0.6832657\ttest: 0.6860206\tbest: 0.6861332 (589)\ttotal: 51.7s\tremaining: 13m 29s\n",
      "700:\tlearn: 0.6880816\ttest: 0.6863476\tbest: 0.6864039 (698)\ttotal: 1m\tremaining: 13m 19s\n",
      "800:\tlearn: 0.6930657\ttest: 0.6866783\tbest: 0.6868923 (778)\ttotal: 1m 8s\tremaining: 13m 9s\n",
      "900:\tlearn: 0.6975270\ttest: 0.6870065\tbest: 0.6872307 (825)\ttotal: 1m 17s\tremaining: 12m 59s\n",
      "1000:\tlearn: 0.7021012\ttest: 0.6873978\tbest: 0.6876681 (994)\ttotal: 1m 25s\tremaining: 12m 48s\n",
      "1100:\tlearn: 0.7061001\ttest: 0.6872098\tbest: 0.6876681 (994)\ttotal: 1m 33s\tremaining: 12m 37s\n",
      "bestTest = 0.6876681337\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6202125\ttest: 0.6200721\tbest: 0.6200721 (0)\ttotal: 91.3ms\tremaining: 15m 13s\n",
      "100:\tlearn: 0.6525028\ttest: 0.6529704\tbest: 0.6529704 (100)\ttotal: 8.96s\tremaining: 14m 38s\n",
      "200:\tlearn: 0.6587961\ttest: 0.6613840\tbest: 0.6613895 (198)\ttotal: 17.9s\tremaining: 14m 30s\n",
      "300:\tlearn: 0.6673138\ttest: 0.6712656\tbest: 0.6712656 (300)\ttotal: 26.5s\tremaining: 14m 13s\n",
      "400:\tlearn: 0.6741639\ttest: 0.6784103\tbest: 0.6784103 (400)\ttotal: 35s\tremaining: 13m 57s\n",
      "500:\tlearn: 0.6797240\ttest: 0.6823391\tbest: 0.6823391 (500)\ttotal: 43.3s\tremaining: 13m 41s\n",
      "600:\tlearn: 0.6849819\ttest: 0.6848060\tbest: 0.6848060 (600)\ttotal: 51.7s\tremaining: 13m 29s\n",
      "700:\tlearn: 0.6898141\ttest: 0.6849961\tbest: 0.6850335 (699)\ttotal: 1m\tremaining: 13m 18s\n",
      "800:\tlearn: 0.6945605\ttest: 0.6857412\tbest: 0.6859243 (780)\ttotal: 1m 8s\tremaining: 13m 8s\n",
      "900:\tlearn: 0.6990471\ttest: 0.6851299\tbest: 0.6859243 (780)\ttotal: 1m 17s\tremaining: 12m 59s\n",
      "bestTest = 0.6859243202\n",
      "bestIteration = 780\n",
      "Shrink model to first 781 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6219064\ttest: 0.6193612\tbest: 0.6193612 (0)\ttotal: 104ms\tremaining: 17m 24s\n",
      "100:\tlearn: 0.6516834\ttest: 0.6488412\tbest: 0.6488412 (100)\ttotal: 9.1s\tremaining: 14m 51s\n",
      "200:\tlearn: 0.6571535\ttest: 0.6548727\tbest: 0.6548727 (200)\ttotal: 18.1s\tremaining: 14m 42s\n",
      "300:\tlearn: 0.6663346\ttest: 0.6654799\tbest: 0.6656001 (295)\ttotal: 26.8s\tremaining: 14m 24s\n",
      "400:\tlearn: 0.6736356\ttest: 0.6721856\tbest: 0.6721856 (400)\ttotal: 35.4s\tremaining: 14m 7s\n",
      "500:\tlearn: 0.6797783\ttest: 0.6761932\tbest: 0.6762363 (499)\ttotal: 43.7s\tremaining: 13m 49s\n",
      "600:\tlearn: 0.6847814\ttest: 0.6788034\tbest: 0.6789287 (597)\ttotal: 52.1s\tremaining: 13m 35s\n",
      "700:\tlearn: 0.6898146\ttest: 0.6806312\tbest: 0.6806312 (700)\ttotal: 1m\tremaining: 13m 26s\n",
      "800:\tlearn: 0.6949283\ttest: 0.6810966\tbest: 0.6811519 (799)\ttotal: 1m 9s\tremaining: 13m 15s\n",
      "900:\tlearn: 0.6995097\ttest: 0.6811392\tbest: 0.6815054 (815)\ttotal: 1m 17s\tremaining: 13m 4s\n",
      "1000:\tlearn: 0.7036841\ttest: 0.6812412\tbest: 0.6817126 (939)\ttotal: 1m 25s\tremaining: 12m 52s\n",
      "1100:\tlearn: 0.7077045\ttest: 0.6814537\tbest: 0.6817126 (939)\ttotal: 1m 34s\tremaining: 12m 40s\n",
      "bestTest = 0.6817125534\n",
      "bestIteration = 939\n",
      "Shrink model to first 940 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6266670\ttest: 0.6247082\tbest: 0.6247082 (0)\ttotal: 97.3ms\tremaining: 16m 12s\n",
      "100:\tlearn: 0.6528941\ttest: 0.6489875\tbest: 0.6489875 (100)\ttotal: 9.02s\tremaining: 14m 44s\n",
      "200:\tlearn: 0.6593034\ttest: 0.6558013\tbest: 0.6560038 (193)\ttotal: 17.9s\tremaining: 14m 34s\n",
      "300:\tlearn: 0.6685413\ttest: 0.6672782\tbest: 0.6672782 (300)\ttotal: 26.6s\tremaining: 14m 16s\n",
      "400:\tlearn: 0.6755164\ttest: 0.6737909\tbest: 0.6737909 (400)\ttotal: 35.1s\tremaining: 14m 1s\n",
      "500:\tlearn: 0.6813258\ttest: 0.6780367\tbest: 0.6780811 (499)\ttotal: 43.5s\tremaining: 13m 44s\n",
      "600:\tlearn: 0.6863240\ttest: 0.6798501\tbest: 0.6798656 (592)\ttotal: 51.9s\tremaining: 13m 31s\n",
      "700:\tlearn: 0.6906659\ttest: 0.6805050\tbest: 0.6805050 (700)\ttotal: 1m\tremaining: 13m 19s\n",
      "800:\tlearn: 0.6957282\ttest: 0.6802605\tbest: 0.6808623 (707)\ttotal: 1m 8s\tremaining: 13m 8s\n",
      "900:\tlearn: 0.7000114\ttest: 0.6808966\tbest: 0.6808966 (900)\ttotal: 1m 17s\tremaining: 12m 57s\n",
      "1000:\tlearn: 0.7041056\ttest: 0.6806491\tbest: 0.6808966 (900)\ttotal: 1m 25s\tremaining: 12m 47s\n",
      "1100:\tlearn: 0.7078214\ttest: 0.6814000\tbest: 0.6815176 (1097)\ttotal: 1m 33s\tremaining: 12m 36s\n",
      "1200:\tlearn: 0.7112085\ttest: 0.6816554\tbest: 0.6818904 (1189)\ttotal: 1m 41s\tremaining: 12m 25s\n",
      "1300:\tlearn: 0.7143868\ttest: 0.6818655\tbest: 0.6819768 (1224)\ttotal: 1m 50s\tremaining: 12m 15s\n",
      "1400:\tlearn: 0.7174308\ttest: 0.6820862\tbest: 0.6822916 (1383)\ttotal: 1m 58s\tremaining: 12m 6s\n",
      "1500:\tlearn: 0.7207714\ttest: 0.6817073\tbest: 0.6822916 (1383)\ttotal: 2m 6s\tremaining: 11m 56s\n",
      "bestTest = 0.682291566\n",
      "bestIteration = 1383\n",
      "Shrink model to first 1384 iterations.\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "models = []\n",
    "\n",
    "\n",
    "models = []\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "\n",
    "    model = CatBoostClassifier(iterations=iterations,\n",
    "                               random_state=SEED,\n",
    "                               task_type=\"GPU\",\n",
    "                               eval_metric=\"F1\",\n",
    "                               cat_features=cat_features,\n",
    "                               one_hot_max_size=4,\n",
    "                               bagging_temperature=0.2,\n",
    "                               depth=10,\n",
    "# depth default 값을 모르겠지만 학습이 엄청 오래걸리게 된다.\n",
    "                               use_best_model=True)\n",
    "    model.fit(x_train.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            early_stopping_rounds=patience ,\n",
    "            verbose = 100\n",
    "        )\n",
    "    \n",
    "    models.append(model)\n",
    "    scores.append(model.get_best_score()[\"validation\"][\"F1\"])\n",
    "    if is_holdout:\n",
    "        break     # 0.6871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = preprocess_data(test_data, cols_equi)\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6886734849641276, 0.6876681337275069, 0.6859243202488102, 0.681712553433618, 0.6822915660322675]\n",
      "0.685254011681266\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "# hyperparemeter 수정 X\n",
    "# 결과 0.75 이전꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7184832593787818, 0.7151081897999327, 0.7119947362997139, 0.7136985421617108, 0.7150238765764664]\n",
      "threshold 0.38 mean 0.7148617208433211\n",
      "[0.7174931062052312, 0.714844634138455, 0.7120086548864045, 0.7134181983503279, 0.7147185825510448]\n",
      "threshold 0.39 mean 0.7144966352262927\n",
      "[0.7169063946723442, 0.7151116671982206, 0.711843523794856, 0.7127521412484178, 0.7140411959689069]\n",
      "threshold 0.4 mean 0.7141309845765491\n",
      "[0.7159854715484489, 0.7146972631997217, 0.7110334473677734, 0.7110486065457814, 0.7129343401070964]\n",
      "threshold 0.41 mean 0.7131398257537644\n",
      "[0.7147870352362188, 0.7125030379725619, 0.7099969255569312, 0.7098220682563363, 0.711525467219775]\n",
      "threshold 0.42 mean 0.7117269068483646\n",
      "max score :  0.7148617208433211\n",
      "fin_threshold :  0.38\n"
     ]
    }
   ],
   "source": [
    "max_score = 0 \n",
    "for threshold in [0.38, 0.39, 0.40, 0.41, 0.42,] :\n",
    "    pred_list = []\n",
    "    scores = []\n",
    "    for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "        pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "        pred = np.where(pred >= threshold , 1, 0)\n",
    "        score = f1_score(y_train[vai],pred)\n",
    "        scores.append(score)\n",
    "        pred = models[i].predict_proba(x_test)[:, 1]\n",
    "        pred_list.append(pred)\n",
    "    print(scores)\n",
    "    print('threshold', threshold, 'mean', np.mean(scores))\n",
    "    if np.mean(scores) > max_score : \n",
    "        max_score = np.mean(scores)\n",
    "        fin_threshold = threshold\n",
    "print(\"max score : \", max_score)\n",
    "print(\"fin_threshold : \", fin_threshold)\n",
    "\n",
    "# 최종모델 threshold 선정 후 다시 pred_list 만들기.\n",
    "for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "    pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "    pred = np.where(pred >= fin_threshold , 1, 0)\n",
    "    score = f1_score(y_train[vai],pred)\n",
    "    scores.append(score)\n",
    "    pred = models[i].predict_proba(x_test)[:, 1]\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hard voting 방법으로 변환한 앙상블\n",
    "\n",
    "count = [0] * len(pred_list[0])\n",
    "for i,pred in enumerate(pred_list) :\n",
    "    for  idx, data in enumerate(pred) :\n",
    "        if data >= threshold :\n",
    "            count[idx] += 1\n",
    "pred = np.where(np.array(count) >= 3, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 1 개수 :  33121\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission\n",
    "print('target 1 개수 : ',sum(sample_submission['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f\"{SUBMIT_PATH}catboost-made4-version2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 똑같은 것을 기존 산술평균 앙상블로 제출한다면?\n",
    "\n",
    "threshold = 0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7174931062052312, 0.714844634138455, 0.7120086548864045, 0.7134181983503279, 0.7147185825510448]\n",
      "0.7144966352262927\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "scores = []\n",
    "for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "    pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "    pred = np.where(pred >= threshold , 1, 0)\n",
    "    score = f1_score(y_train[vai],pred)\n",
    "    scores.append(score)\n",
    "    pred = models[i].predict_proba(x_test)[:, 1]\n",
    "    pred_list.append(pred)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.mean( pred_list , axis = 0 )\n",
    "pred = np.where(pred >= threshold , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 1 개수 :  34371\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission\n",
    "print('target 1 개수 : ',sum(sample_submission['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f\"{SUBMIT_PATH}catboost-made4-version3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c97dde18f122f9d21c34c8255baf2515d19df3edbb55cbf82035c58b5acf6190"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
