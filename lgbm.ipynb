{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- depth + bagging_temperature + 더 깊게 학습하게 만들기.\n",
    "- 해볼 것\n",
    "-> bagging_temperature 이란?\n",
    "-> 더 깊게 학습하는 방법은?\n",
    "-> overtfittign 을 막을 수 있는 방법은?\n",
    "\n",
    "---\n",
    "- model 5개의 평균을 만들어서 평가하고 있는데, 그 중 가장 좋은 model로 값을 뽑아내면 좋지 않을까?\n",
    "\n",
    "- threshold 를 for 문 구간을 통해서 구하게 변경\n",
    "\n",
    "- 산술평균 앙상블 대신에, threshold 값을 기준으로 하드보팅 앙상블 방법으로 진행해보는 것은 어떨까?\n",
    "-> threshold 인 pred_proba가 0.4 이상인 값이 3개 이상이라면 True 같은 느낌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "SUBMIT_PATH = \"submit/\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import random\n",
    "import math\n",
    "from typing import List ,Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "import sklearn \n",
    "from sklearn.model_selection import StratifiedKFold , KFold\n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "from catboost import Pool,CatBoostClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 35), (46404, 34))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(f'{DATA_PATH}train.csv')\n",
    "test_data = pd.read_csv(f'{DATA_PATH}test.csv')\n",
    "\n",
    "\n",
    "train_data.shape , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_l_match_yn</th>\n",
       "      <th>d_m_match_yn</th>\n",
       "      <th>d_s_match_yn</th>\n",
       "      <th>h_l_match_yn</th>\n",
       "      <th>h_m_match_yn</th>\n",
       "      <th>h_s_match_yn</th>\n",
       "      <th>person_attribute_a</th>\n",
       "      <th>person_attribute_a_1</th>\n",
       "      <th>person_attribute_b</th>\n",
       "      <th>...</th>\n",
       "      <th>contents_attribute_l</th>\n",
       "      <th>contents_attribute_d</th>\n",
       "      <th>contents_attribute_m</th>\n",
       "      <th>contents_attribute_e</th>\n",
       "      <th>contents_attribute_h</th>\n",
       "      <th>person_rn</th>\n",
       "      <th>contents_rn</th>\n",
       "      <th>contents_open_dt</th>\n",
       "      <th>target</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>618822</td>\n",
       "      <td>354805</td>\n",
       "      <td>2020-01-17 12:09:36</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>571659</td>\n",
       "      <td>346213</td>\n",
       "      <td>2020-06-18 17:48:52</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1600</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>399816</td>\n",
       "      <td>206408</td>\n",
       "      <td>2020-07-08 20:00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  d_l_match_yn  d_m_match_yn  d_s_match_yn  h_l_match_yn  h_m_match_yn  \\\n",
       "0   0          True          True          True         False         False   \n",
       "1   1         False         False         False          True          True   \n",
       "2   2         False         False         False          True         False   \n",
       "\n",
       "   h_s_match_yn  person_attribute_a  person_attribute_a_1  person_attribute_b  \\\n",
       "0         False                   1                     4                   3   \n",
       "1         False                   1                     3                   4   \n",
       "2         False                   2                     0                   3   \n",
       "\n",
       "   ...  contents_attribute_l  contents_attribute_d  contents_attribute_m  \\\n",
       "0  ...                  1608                   275                     1   \n",
       "1  ...                  1608                   275                     1   \n",
       "2  ...                  1600                    94                     1   \n",
       "\n",
       "   contents_attribute_e  contents_attribute_h  person_rn  contents_rn  \\\n",
       "0                     4                   139     618822       354805   \n",
       "1                     4                   133     571659       346213   \n",
       "2                     4                    53     399816       206408   \n",
       "\n",
       "     contents_open_dt  target  hour  \n",
       "0 2020-01-17 12:09:36       1    12  \n",
       "1 2020-06-18 17:48:52       0    17  \n",
       "2 2020-07-08 20:00:10       0    20  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hour 변수를 넣기 위해서 추가\n",
    "train_data['contents_open_dt'] = train_data['contents_open_dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "test_data['contents_open_dt'] = test_data['contents_open_dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "train_data['hour'] = train_data['contents_open_dt'].apply(lambda x : x.timetuple()[3])\n",
    "test_data['hour'] = test_data['contents_open_dt'].apply(lambda x : x.timetuple()[3])\n",
    "\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data EDA에 따라서\n",
    "# good - mid - low time (target에 따라서 good <-> low 범위)\n",
    "# low : 23~07\n",
    "# mid : 17~22\n",
    "# good : 8~16\n",
    "train_data.loc[train_data['hour']<=7, 'hour_band'] = 1 # 'low_time'\n",
    "train_data.loc[train_data['hour']==23, 'hour_band'] = 1 #'low_time'\n",
    "\n",
    "train_data.loc[(train_data['hour']>7) & (train_data['hour'] <= 16), 'hour_band'] = 3 # 'good_time'\n",
    "train_data.loc[(train_data['hour']>=17) & (train_data['hour']<=22), 'hour_band'] = 2#'mid_time'\n",
    "train_data = train_data.drop(columns = ['hour'])\n",
    "\n",
    "test_data.loc[test_data['hour']<=7, 'hour_band'] = 1#'low_time'\n",
    "test_data.loc[test_data['hour']==23, 'hour_band'] = 1#'low_time'\n",
    "\n",
    "test_data.loc[(test_data['hour']>7) & (test_data['hour'] <= 16), 'hour_band'] = 3#'good_time'\n",
    "test_data.loc[(test_data['hour']>=17) & (test_data['hour']<=22), 'hour_band'] = 2#'mid_time'\n",
    "test_data = test_data.drop(columns = ['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def add_code(\n",
    "    df: pd.DataFrame,\n",
    "    d_code: Dict[int, Dict[str, int]], \n",
    "    h_code: Dict[int, Dict[str, int]], \n",
    "    l_code: Dict[int, Dict[str, int]],\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # Copy input data\n",
    "    df = df.copy()   \n",
    "\n",
    "    # D Code\n",
    "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    # H Code\n",
    "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    \n",
    "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    \n",
    "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "\n",
    "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "\n",
    "    # L Code\n",
    "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
    "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
    "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
    "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_code = pd.read_csv('data/속성_D_코드.csv', index_col=0).T.to_dict()\n",
    "h_code = pd.read_csv('data/속성_H_코드.csv', index_col=0).T.to_dict()\n",
    "l_code = pd.read_csv('data/속성_L_코드.csv', index_col=0).T.to_dict()\n",
    "\n",
    "\n",
    "train_data = add_code(train_data, d_code, h_code, l_code)\n",
    "test_data = add_code(test_data, d_code, h_code, l_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'd_l_match_yn', 'd_m_match_yn', 'd_s_match_yn', 'h_l_match_yn',\n",
       "       'h_m_match_yn', 'h_s_match_yn', 'person_attribute_a',\n",
       "       'person_attribute_a_1', 'person_attribute_b', 'person_prefer_c',\n",
       "       'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
       "       'person_prefer_e', 'person_prefer_f', 'person_prefer_g',\n",
       "       'person_prefer_h_1', 'person_prefer_h_2', 'person_prefer_h_3',\n",
       "       'contents_attribute_i', 'contents_attribute_a',\n",
       "       'contents_attribute_j_1', 'contents_attribute_j',\n",
       "       'contents_attribute_c', 'contents_attribute_k', 'contents_attribute_l',\n",
       "       'contents_attribute_d', 'contents_attribute_m', 'contents_attribute_e',\n",
       "       'contents_attribute_h', 'person_rn', 'contents_rn', 'contents_open_dt',\n",
       "       'target', 'hour_band', 'person_prefer_d_1_n', 'person_prefer_d_1_s',\n",
       "       'person_prefer_d_1_m', 'person_prefer_d_1_l', 'person_prefer_d_2_n',\n",
       "       'person_prefer_d_2_s', 'person_prefer_d_2_m', 'person_prefer_d_2_l',\n",
       "       'person_prefer_d_3_n', 'person_prefer_d_3_s', 'person_prefer_d_3_m',\n",
       "       'person_prefer_d_3_l', 'contents_attribute_d_n',\n",
       "       'contents_attribute_d_s', 'contents_attribute_d_m',\n",
       "       'contents_attribute_d_l', 'person_prefer_h_1_l', 'person_prefer_h_1_m',\n",
       "       'person_prefer_h_2_l', 'person_prefer_h_2_m', 'person_prefer_h_3_l',\n",
       "       'person_prefer_h_3_m', 'contents_attribute_h_l',\n",
       "       'contents_attribute_h_m', 'contents_attribute_l_n',\n",
       "       'contents_attribute_l_s', 'contents_attribute_l_m',\n",
       "       'contents_attribute_l_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = [\"id\",\"person_prefer_f\",\"person_prefer_g\" ,\"contents_open_dt\", \"contents_rn\", ]\n",
    "\n",
    "train_data = train_data.drop(columns = cols_drop)\n",
    "test_data = test_data.drop(columns = cols_drop)\n",
    "\n",
    "\n",
    "# x_train, y_train = preprocess_data(train_data, cols_merge = cols_merge , cols_equi= cols_equi , cols_drop = cols_drop)\n",
    "# x_test, _ = preprocess_data(test_data,is_train = False, cols_merge = cols_merge , cols_equi= cols_equi  , cols_drop = cols_drop)\n",
    "# x_train.shape , y_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분을 추가한 모델이 성능이 조금은 더 높더라.\n",
    "# 변수 개수가 여기에서 차이가 난다.\n",
    "cols_equi = [\n",
    "\n",
    "    (\"contents_attribute_c\",\"person_prefer_c\"),\n",
    "    (\"contents_attribute_e\",\"person_prefer_e\"),\n",
    "\n",
    "    (\"person_prefer_d_2_s\" , \"contents_attribute_d_s\"),\n",
    "    (\"person_prefer_d_2_m\" , \"contents_attribute_d_m\"),\n",
    "    (\"person_prefer_d_2_l\" , \"contents_attribute_d_l\"),\n",
    "    (\"person_prefer_d_3_s\" , \"contents_attribute_d_s\"),\n",
    "    (\"person_prefer_d_3_m\" , \"contents_attribute_d_m\"),\n",
    "    (\"person_prefer_d_3_l\" , \"contents_attribute_d_l\"),\n",
    "\n",
    "    (\"person_prefer_h_1_m\" , \"contents_attribute_h_m\"),\n",
    "    (\"person_prefer_h_2_m\" , \"contents_attribute_h_m\"),\n",
    "    (\"person_prefer_h_3_m\" , \"contents_attribute_h_m\"),\n",
    "    (\"person_prefer_h_1_l\" , \"contents_attribute_h_l\"),\n",
    "    (\"person_prefer_h_2_l\" , \"contents_attribute_h_l\"),\n",
    "    (\"person_prefer_h_3_l\" , \"contents_attribute_h_l\"),\n",
    "]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = ['d_l_match_yn',\t'd_m_match_yn',\t'd_s_match_yn'\t,'h_l_match_yn','h_m_match_yn',\t'h_s_match_yn',\t'person_attribute_a']\n",
    "def preprocess_data(\n",
    "                    df:pd.DataFrame,\n",
    "                    cols_equi:List[Tuple[str,str]]= [] )->Tuple[pd.DataFrame,np.ndarray]:\n",
    "    df = df.copy()\n",
    "\n",
    "\n",
    "    cols = df.select_dtypes(bool).columns.tolist()\n",
    "    df[cols] = df[cols].astype(int)\n",
    "\n",
    "    for col1, col2 in cols_equi:\n",
    "        df[f\"{col1}_{col2}\"] = (df[col1] == df[col2] ).astype(int)\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d_l_match_yn', 'd_m_match_yn', 'd_s_match_yn', 'h_l_match_yn',\n",
       "       'h_m_match_yn', 'h_s_match_yn', 'person_attribute_a',\n",
       "       'person_attribute_a_1', 'person_attribute_b', 'person_prefer_c',\n",
       "       'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
       "       'person_prefer_e', 'person_prefer_h_1', 'person_prefer_h_2',\n",
       "       'person_prefer_h_3', 'contents_attribute_i', 'contents_attribute_a',\n",
       "       'contents_attribute_j_1', 'contents_attribute_j',\n",
       "       'contents_attribute_c', 'contents_attribute_k', 'contents_attribute_l',\n",
       "       'contents_attribute_d', 'contents_attribute_m', 'contents_attribute_e',\n",
       "       'contents_attribute_h', 'person_rn', 'target', 'hour_band',\n",
       "       'person_prefer_d_1_n', 'person_prefer_d_1_s', 'person_prefer_d_1_m',\n",
       "       'person_prefer_d_1_l', 'person_prefer_d_2_n', 'person_prefer_d_2_s',\n",
       "       'person_prefer_d_2_m', 'person_prefer_d_2_l', 'person_prefer_d_3_n',\n",
       "       'person_prefer_d_3_s', 'person_prefer_d_3_m', 'person_prefer_d_3_l',\n",
       "       'contents_attribute_d_n', 'contents_attribute_d_s',\n",
       "       'contents_attribute_d_m', 'contents_attribute_d_l',\n",
       "       'person_prefer_h_1_l', 'person_prefer_h_1_m', 'person_prefer_h_2_l',\n",
       "       'person_prefer_h_2_m', 'person_prefer_h_3_l', 'person_prefer_h_3_m',\n",
       "       'contents_attribute_h_l', 'contents_attribute_h_m',\n",
       "       'contents_attribute_l_n', 'contents_attribute_l_s',\n",
       "       'contents_attribute_l_m', 'contents_attribute_l_l',\n",
       "       'contents_attribute_c_person_prefer_c',\n",
       "       'contents_attribute_e_person_prefer_e',\n",
       "       'person_prefer_d_2_s_contents_attribute_d_s',\n",
       "       'person_prefer_d_2_m_contents_attribute_d_m',\n",
       "       'person_prefer_d_2_l_contents_attribute_d_l',\n",
       "       'person_prefer_d_3_s_contents_attribute_d_s',\n",
       "       'person_prefer_d_3_m_contents_attribute_d_m',\n",
       "       'person_prefer_d_3_l_contents_attribute_d_l',\n",
       "       'person_prefer_h_1_m_contents_attribute_h_m',\n",
       "       'person_prefer_h_2_m_contents_attribute_h_m',\n",
       "       'person_prefer_h_3_m_contents_attribute_h_m',\n",
       "       'person_prefer_h_1_l_contents_attribute_h_l',\n",
       "       'person_prefer_h_2_l_contents_attribute_h_l',\n",
       "       'person_prefer_h_3_l_contents_attribute_h_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data(train_data, cols_equi).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_data(train_data, cols_equi)\n",
    "test_data = preprocess_data(test_data, cols_equi)\n",
    "\n",
    "y_train = train_data.pop('target')\n",
    "x_train = train_data\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = x_train.columns[x_train.nunique() > 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person_attribute_a_1',\n",
       " 'person_attribute_b',\n",
       " 'person_prefer_c',\n",
       " 'person_prefer_d_1',\n",
       " 'person_prefer_d_2',\n",
       " 'person_prefer_d_3',\n",
       " 'person_prefer_e',\n",
       " 'person_prefer_h_1',\n",
       " 'person_prefer_h_2',\n",
       " 'person_prefer_h_3',\n",
       " 'contents_attribute_i',\n",
       " 'contents_attribute_a',\n",
       " 'contents_attribute_j_1',\n",
       " 'contents_attribute_c',\n",
       " 'contents_attribute_l',\n",
       " 'contents_attribute_d',\n",
       " 'contents_attribute_m',\n",
       " 'contents_attribute_e',\n",
       " 'contents_attribute_h',\n",
       " 'person_rn',\n",
       " 'hour_band',\n",
       " 'person_prefer_d_1_n',\n",
       " 'person_prefer_d_1_s',\n",
       " 'person_prefer_d_1_m',\n",
       " 'person_prefer_d_1_l',\n",
       " 'person_prefer_d_2_n',\n",
       " 'person_prefer_d_2_s',\n",
       " 'person_prefer_d_2_m',\n",
       " 'person_prefer_d_2_l',\n",
       " 'person_prefer_d_3_n',\n",
       " 'person_prefer_d_3_s',\n",
       " 'person_prefer_d_3_m',\n",
       " 'person_prefer_d_3_l',\n",
       " 'contents_attribute_d_n',\n",
       " 'contents_attribute_d_s',\n",
       " 'contents_attribute_d_m',\n",
       " 'contents_attribute_d_l',\n",
       " 'person_prefer_h_1_l',\n",
       " 'person_prefer_h_1_m',\n",
       " 'person_prefer_h_2_l',\n",
       " 'person_prefer_h_2_m',\n",
       " 'person_prefer_h_3_l',\n",
       " 'person_prefer_h_3_m',\n",
       " 'contents_attribute_h_l',\n",
       " 'contents_attribute_h_m',\n",
       " 'contents_attribute_l_n',\n",
       " 'contents_attribute_l_s',\n",
       " 'contents_attribute_l_m',\n",
       " 'contents_attribute_l_l']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "n_splits = 5 # 기존 5\n",
    "iterations = 10000 # 기존 3000\n",
    "patience = 200\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3.0\n",
       "1         2.0\n",
       "2         2.0\n",
       "3         2.0\n",
       "4         2.0\n",
       "         ... \n",
       "501946    3.0\n",
       "501947    3.0\n",
       "501948    2.0\n",
       "501949    3.0\n",
       "501950    3.0\n",
       "Name: hour_band, Length: 501951, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['hour_band']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.645452\n",
      "[200]\tvalid_0's binary_logloss: 0.64154\n",
      "[300]\tvalid_0's binary_logloss: 0.639518\n",
      "[400]\tvalid_0's binary_logloss: 0.638075\n",
      "[500]\tvalid_0's binary_logloss: 0.637177\n",
      "[600]\tvalid_0's binary_logloss: 0.636678\n",
      "[700]\tvalid_0's binary_logloss: 0.636119\n",
      "[800]\tvalid_0's binary_logloss: 0.63557\n",
      "[900]\tvalid_0's binary_logloss: 0.635047\n",
      "[1000]\tvalid_0's binary_logloss: 0.634648\n",
      "[1100]\tvalid_0's binary_logloss: 0.634356\n",
      "[1200]\tvalid_0's binary_logloss: 0.634037\n",
      "[1300]\tvalid_0's binary_logloss: 0.633789\n",
      "[1400]\tvalid_0's binary_logloss: 0.633564\n",
      "[1500]\tvalid_0's binary_logloss: 0.633315\n",
      "[1600]\tvalid_0's binary_logloss: 0.633243\n",
      "[1700]\tvalid_0's binary_logloss: 0.633105\n",
      "[1800]\tvalid_0's binary_logloss: 0.633071\n",
      "[1900]\tvalid_0's binary_logloss: 0.632891\n",
      "[2000]\tvalid_0's binary_logloss: 0.632707\n",
      "[2100]\tvalid_0's binary_logloss: 0.632578\n",
      "[2200]\tvalid_0's binary_logloss: 0.632486\n",
      "[2300]\tvalid_0's binary_logloss: 0.63243\n",
      "[2400]\tvalid_0's binary_logloss: 0.632404\n",
      "[2500]\tvalid_0's binary_logloss: 0.632293\n",
      "[2600]\tvalid_0's binary_logloss: 0.632309\n",
      "[2700]\tvalid_0's binary_logloss: 0.632202\n",
      "[2800]\tvalid_0's binary_logloss: 0.632196\n",
      "[2900]\tvalid_0's binary_logloss: 0.632221\n",
      "0.772542326499161\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.646528\n",
      "[200]\tvalid_0's binary_logloss: 0.642488\n",
      "[300]\tvalid_0's binary_logloss: 0.64061\n",
      "[400]\tvalid_0's binary_logloss: 0.639416\n",
      "[500]\tvalid_0's binary_logloss: 0.638427\n",
      "[600]\tvalid_0's binary_logloss: 0.637709\n",
      "[700]\tvalid_0's binary_logloss: 0.637109\n",
      "[800]\tvalid_0's binary_logloss: 0.636563\n",
      "[900]\tvalid_0's binary_logloss: 0.636174\n",
      "[1000]\tvalid_0's binary_logloss: 0.63579\n",
      "[1100]\tvalid_0's binary_logloss: 0.635406\n",
      "[1200]\tvalid_0's binary_logloss: 0.635202\n",
      "[1300]\tvalid_0's binary_logloss: 0.635039\n",
      "[1400]\tvalid_0's binary_logloss: 0.634746\n",
      "[1500]\tvalid_0's binary_logloss: 0.634683\n",
      "[1600]\tvalid_0's binary_logloss: 0.634549\n",
      "[1700]\tvalid_0's binary_logloss: 0.634331\n",
      "[1800]\tvalid_0's binary_logloss: 0.634345\n",
      "[1900]\tvalid_0's binary_logloss: 0.634206\n",
      "[2000]\tvalid_0's binary_logloss: 0.634244\n",
      "[2100]\tvalid_0's binary_logloss: 0.634188\n",
      "[2200]\tvalid_0's binary_logloss: 0.634075\n",
      "[2300]\tvalid_0's binary_logloss: 0.633989\n",
      "[2400]\tvalid_0's binary_logloss: 0.633879\n",
      "[2500]\tvalid_0's binary_logloss: 0.63384\n",
      "[2600]\tvalid_0's binary_logloss: 0.633845\n",
      "[2700]\tvalid_0's binary_logloss: 0.633956\n",
      "0.7648958857498862\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.646029\n",
      "[200]\tvalid_0's binary_logloss: 0.642612\n",
      "[300]\tvalid_0's binary_logloss: 0.6409\n",
      "[400]\tvalid_0's binary_logloss: 0.639777\n",
      "[500]\tvalid_0's binary_logloss: 0.639047\n",
      "[600]\tvalid_0's binary_logloss: 0.63808\n",
      "[700]\tvalid_0's binary_logloss: 0.637439\n",
      "[800]\tvalid_0's binary_logloss: 0.636926\n",
      "[900]\tvalid_0's binary_logloss: 0.636555\n",
      "[1000]\tvalid_0's binary_logloss: 0.636215\n",
      "[1100]\tvalid_0's binary_logloss: 0.635747\n",
      "[1200]\tvalid_0's binary_logloss: 0.635472\n",
      "[1300]\tvalid_0's binary_logloss: 0.635141\n",
      "[1400]\tvalid_0's binary_logloss: 0.634916\n",
      "[1500]\tvalid_0's binary_logloss: 0.634547\n",
      "[1600]\tvalid_0's binary_logloss: 0.634389\n",
      "[1700]\tvalid_0's binary_logloss: 0.634081\n",
      "[1800]\tvalid_0's binary_logloss: 0.634007\n",
      "[1900]\tvalid_0's binary_logloss: 0.633869\n",
      "[2000]\tvalid_0's binary_logloss: 0.633812\n",
      "[2100]\tvalid_0's binary_logloss: 0.633741\n",
      "[2200]\tvalid_0's binary_logloss: 0.633703\n",
      "[2300]\tvalid_0's binary_logloss: 0.633642\n",
      "[2400]\tvalid_0's binary_logloss: 0.633528\n",
      "[2500]\tvalid_0's binary_logloss: 0.633488\n",
      "[2600]\tvalid_0's binary_logloss: 0.633498\n",
      "[2700]\tvalid_0's binary_logloss: 0.633497\n",
      "[2800]\tvalid_0's binary_logloss: 0.633484\n",
      "[2900]\tvalid_0's binary_logloss: 0.633379\n",
      "[3000]\tvalid_0's binary_logloss: 0.633436\n",
      "0.7787324095218736\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.648045\n",
      "[200]\tvalid_0's binary_logloss: 0.644234\n",
      "[300]\tvalid_0's binary_logloss: 0.642164\n",
      "[400]\tvalid_0's binary_logloss: 0.641007\n",
      "[500]\tvalid_0's binary_logloss: 0.640025\n",
      "[600]\tvalid_0's binary_logloss: 0.639282\n",
      "[700]\tvalid_0's binary_logloss: 0.638596\n",
      "[800]\tvalid_0's binary_logloss: 0.637974\n",
      "[900]\tvalid_0's binary_logloss: 0.637542\n",
      "[1000]\tvalid_0's binary_logloss: 0.637022\n",
      "[1100]\tvalid_0's binary_logloss: 0.636675\n",
      "[1200]\tvalid_0's binary_logloss: 0.636323\n",
      "[1300]\tvalid_0's binary_logloss: 0.636036\n",
      "[1400]\tvalid_0's binary_logloss: 0.635764\n",
      "[1500]\tvalid_0's binary_logloss: 0.635592\n",
      "[1600]\tvalid_0's binary_logloss: 0.635401\n",
      "[1700]\tvalid_0's binary_logloss: 0.635051\n",
      "[1800]\tvalid_0's binary_logloss: 0.634917\n",
      "[1900]\tvalid_0's binary_logloss: 0.634802\n",
      "[2000]\tvalid_0's binary_logloss: 0.634811\n",
      "[2100]\tvalid_0's binary_logloss: 0.634732\n",
      "[2200]\tvalid_0's binary_logloss: 0.634626\n",
      "[2300]\tvalid_0's binary_logloss: 0.634593\n",
      "[2400]\tvalid_0's binary_logloss: 0.634531\n",
      "[2500]\tvalid_0's binary_logloss: 0.634503\n",
      "[2600]\tvalid_0's binary_logloss: 0.634501\n",
      "[2700]\tvalid_0's binary_logloss: 0.634439\n",
      "[2800]\tvalid_0's binary_logloss: 0.634462\n",
      "[2900]\tvalid_0's binary_logloss: 0.634338\n",
      "[3000]\tvalid_0's binary_logloss: 0.634369\n",
      "0.7776148875777694\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.64679\n",
      "[200]\tvalid_0's binary_logloss: 0.643032\n",
      "[300]\tvalid_0's binary_logloss: 0.640899\n",
      "[400]\tvalid_0's binary_logloss: 0.63951\n",
      "[500]\tvalid_0's binary_logloss: 0.638483\n",
      "[600]\tvalid_0's binary_logloss: 0.637885\n",
      "[700]\tvalid_0's binary_logloss: 0.637206\n",
      "[800]\tvalid_0's binary_logloss: 0.636623\n",
      "[900]\tvalid_0's binary_logloss: 0.636134\n",
      "[1000]\tvalid_0's binary_logloss: 0.635875\n",
      "[1100]\tvalid_0's binary_logloss: 0.63563\n",
      "[1200]\tvalid_0's binary_logloss: 0.63517\n",
      "[1300]\tvalid_0's binary_logloss: 0.634827\n",
      "[1400]\tvalid_0's binary_logloss: 0.634625\n",
      "[1500]\tvalid_0's binary_logloss: 0.634395\n",
      "[1600]\tvalid_0's binary_logloss: 0.63413\n",
      "[1700]\tvalid_0's binary_logloss: 0.63392\n",
      "[1800]\tvalid_0's binary_logloss: 0.633835\n",
      "[1900]\tvalid_0's binary_logloss: 0.633646\n",
      "[2000]\tvalid_0's binary_logloss: 0.63359\n",
      "[2100]\tvalid_0's binary_logloss: 0.633595\n",
      "0.74647115187514\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "    \n",
    "    model = lgb.LGBMClassifier(n_estimators = 3000)\n",
    "    model.fit(x_train.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            eval_metric = 'F1',\n",
    "            early_stopping_rounds=patience ,\n",
    "            verbose = 100\n",
    "        )    \n",
    "    y_pred = model.predict(x_train.iloc[tri])\n",
    "    f1 = f1_score(y_train[tri], y_pred)\n",
    "    print(f1)\n",
    "\n",
    "    \n",
    "    models.append(model)   \n",
    "\n",
    "    if is_holdout:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = models[3].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25092"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 1 개수 :  25092\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission\n",
    "print('target 1 개수 : ',sum(sample_submission['target']))\n",
    "sample_submission.to_csv(f\"{SUBMIT_PATH}lgbm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category 로 변수를 바꾸고 나서 진행하면 성능이 좋아진다?\n",
    "https://dataplay.tistory.com/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_data(train_data, cols_equi)\n",
    "test_data = preprocess_data(test_data, cols_equi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data.columns : \n",
    "    if i != 'target' :\n",
    "        train_data[i] = train_data[i].astype('category') \n",
    "        test_data[i] = test_data[i].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.pop('target')\n",
    "x_train = train_data\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "n_splits = 5 # 기존 5\n",
    "iterations = 10000 # 기존 3000\n",
    "patience = 200\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isds/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/isds/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/isds/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/isds/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.637838\n",
      "[200]\tvalid_0's binary_logloss: 0.635776\n",
      "[300]\tvalid_0's binary_logloss: 0.635257\n",
      "[400]\tvalid_0's binary_logloss: 0.635593\n",
      "[500]\tvalid_0's binary_logloss: 0.636043\n",
      "0.7620066090542116\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.640515\n",
      "[200]\tvalid_0's binary_logloss: 0.638915\n",
      "[300]\tvalid_0's binary_logloss: 0.638486\n",
      "[400]\tvalid_0's binary_logloss: 0.638488\n",
      "0.7538749582400996\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.640144\n",
      "[200]\tvalid_0's binary_logloss: 0.638385\n",
      "[300]\tvalid_0's binary_logloss: 0.637962\n",
      "[400]\tvalid_0's binary_logloss: 0.63821\n",
      "0.7559572838195776\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.641665\n",
      "[200]\tvalid_0's binary_logloss: 0.639807\n",
      "[300]\tvalid_0's binary_logloss: 0.639733\n",
      "[400]\tvalid_0's binary_logloss: 0.640398\n",
      "0.7488860223732349\n",
      "==================================================\n",
      "[100]\tvalid_0's binary_logloss: 0.640807\n",
      "[200]\tvalid_0's binary_logloss: 0.638739\n",
      "[300]\tvalid_0's binary_logloss: 0.638754\n",
      "[400]\tvalid_0's binary_logloss: 0.639264\n",
      "0.7460315559270961\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "    \n",
    "    model = lgb.LGBMClassifier(n_estimators = 3000)\n",
    "    model.fit(x_train.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            eval_metric = 'F1',\n",
    "            early_stopping_rounds=patience ,\n",
    "            verbose = 100\n",
    "        )    \n",
    "    y_pred = model.predict(x_train.iloc[tri])\n",
    "    f1 = f1_score(y_train[tri], y_pred)\n",
    "    print(f1)\n",
    "\n",
    "    \n",
    "    models.append(model)   \n",
    "\n",
    "    if is_holdout:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = models[0].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24692"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 1 개수 :  24692\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission\n",
    "print('target 1 개수 : ',sum(sample_submission['target']))\n",
    "sample_submission.to_csv(f\"{SUBMIT_PATH}lgbm2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-dec77b7c9880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     model.fit(x_train.iloc[tri], y_train[tri], \n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvai\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvai\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0meval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmade_F1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[1;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   3269\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m         \"\"\"\n\u001b[0;32m-> 3271\u001b[0;31m         return [item for i in range(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   3272\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   3273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3270\u001b[0m         \"\"\"\n\u001b[1;32m   3271\u001b[0m         return [item for i in range(1, self.__num_dataset)\n\u001b[0;32m-> 3272\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   3273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   3807\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m                 \u001b[0mfeval_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0meval_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_higher_better\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, preds, dataset)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0margc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0margc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-dec77b7c9880>\u001b[0m in \u001b[0;36mmade_F1\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmade_F1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvai\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \"\"\"\n\u001b[0;32m-> 1044\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \"\"\"\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1169\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1434\u001b[0m                                     pos_label)\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                          str(average_options))\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "def made_F1(y_true, y_pred) :\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "    \n",
    "    model = lgb.LGBMClassifier(n_estimators = 300)\n",
    "    model.fit(x_train.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            eval_metric = made_F1,\n",
    "            early_stopping_rounds=patience ,\n",
    "            verbose = 100\n",
    "        )    \n",
    "    y_pred = model.predict(x_train.iloc[tri])\n",
    "    f1 = f1_score(y_train[tri], y_pred)\n",
    "    print(f1)\n",
    "\n",
    "    \n",
    "    models.append(model)   \n",
    "\n",
    "    if is_holdout:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "models = []\n",
    "\n",
    "\n",
    "models = []\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "\n",
    "    model = CatBoostClassifier(iterations=iterations,\n",
    "                               random_state=SEED,\n",
    "                               task_type=\"GPU\",\n",
    "                               eval_metric=\"F1\",\n",
    "                               cat_features=cat_features,\n",
    "                               one_hot_max_size=4,\n",
    "                               bagging_temperature=0.2,\n",
    "                               depth=10,\n",
    "# depth default 값을 모르겠지만 학습이 엄청 오래걸리게 된다.\n",
    "                               use_best_model=True)\n",
    "    model.fit(x_train.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            early_stopping_rounds=patience ,\n",
    "            verbose = 100\n",
    "        )\n",
    "    \n",
    "    models.append(model)\n",
    "    scores.append(model.get_best_score()[\"validation\"][\"F1\"])\n",
    "    if is_holdout:\n",
    "        break     # 0.6871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-1020e25844e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LightGBM Model accuracy score: {0:0.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Logloss' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Logloss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7472e5f89af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m lgbm_scores = cross_val_score(lgbm, X, y,\n\u001b[0m\u001b[1;32m     22\u001b[0m                               \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Logloss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                               \u001b[0;31m#scoring=\"neg_mean_squared_error\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[1;32m    398\u001b[0m     \u001b[0;31m# To ensure multimetric format is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    403\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/isds/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0m\u001b[1;32m    363\u001b[0m                              \u001b[0;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                              'to get valid options.' % scoring)\n",
      "\u001b[0;31mValueError\u001b[0m: 'Logloss' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = x_train\n",
    "y = y_train\n",
    "\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf = lgb.LGBMClassifier()\n",
    "\n",
    "lgbm = lightgbm.LGBMRegressor(boosting_type='gbdt',\n",
    "                              max_depth=3,\n",
    "                              n_estimators=3000,\n",
    "                              learning_rate=0.1,\n",
    "                              objective='Logloss',\n",
    "                              n_jobs=-1, random_state=0)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, X, y,\n",
    "                              scoring = 'Logloss',\n",
    "                              #scoring=\"neg_mean_squared_error\",\n",
    "                              cv=5, n_jobs=1)\n",
    "\n",
    "lgbm_rmse = np.sqrt(-lgbm_scores)\n",
    "print(\"Cross-validated RMSE for LightGBM: \", np.mean(lgbm_rmse))\n",
    "\n",
    "end = time.time()\n",
    "diff = end - start\n",
    "print('Execution time for LightGBM (in Seconds):', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6208467\ttest: 0.6196185\tbest: 0.6196185 (0)\ttotal: 104ms\tremaining: 17m 19s\n",
      "100:\tlearn: 0.6514052\ttest: 0.6550750\tbest: 0.6550750 (100)\ttotal: 8.94s\tremaining: 14m 35s\n",
      "200:\tlearn: 0.6577890\ttest: 0.6607306\tbest: 0.6608856 (196)\ttotal: 17.8s\tremaining: 14m 28s\n",
      "300:\tlearn: 0.6662070\ttest: 0.6724514\tbest: 0.6724514 (300)\ttotal: 26.4s\tremaining: 14m 9s\n",
      "400:\tlearn: 0.6737380\ttest: 0.6790632\tbest: 0.6790632 (400)\ttotal: 34.8s\tremaining: 13m 53s\n",
      "500:\tlearn: 0.6794737\ttest: 0.6842533\tbest: 0.6842950 (499)\ttotal: 43.2s\tremaining: 13m 39s\n",
      "600:\tlearn: 0.6848177\ttest: 0.6863817\tbest: 0.6863817 (600)\ttotal: 51.6s\tremaining: 13m 26s\n",
      "700:\tlearn: 0.6898518\ttest: 0.6877063\tbest: 0.6877359 (693)\ttotal: 60s\tremaining: 13m 15s\n",
      "800:\tlearn: 0.6948310\ttest: 0.6885246\tbest: 0.6886186 (770)\ttotal: 1m 8s\tremaining: 13m 5s\n",
      "900:\tlearn: 0.6992347\ttest: 0.6884749\tbest: 0.6886186 (770)\ttotal: 1m 16s\tremaining: 12m 53s\n",
      "1000:\tlearn: 0.7034139\ttest: 0.6882876\tbest: 0.6886197 (924)\ttotal: 1m 24s\tremaining: 12m 43s\n",
      "1100:\tlearn: 0.7071869\ttest: 0.6882177\tbest: 0.6886197 (924)\ttotal: 1m 33s\tremaining: 12m 32s\n",
      "1200:\tlearn: 0.7106345\ttest: 0.6884967\tbest: 0.6886735 (1185)\ttotal: 1m 41s\tremaining: 12m 22s\n",
      "1300:\tlearn: 0.7139070\ttest: 0.6883357\tbest: 0.6886735 (1185)\ttotal: 1m 49s\tremaining: 12m 12s\n",
      "bestTest = 0.688673485\n",
      "bestIteration = 1185\n",
      "Shrink model to first 1186 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6185772\ttest: 0.6211568\tbest: 0.6211568 (0)\ttotal: 104ms\tremaining: 17m 23s\n",
      "100:\tlearn: 0.6503384\ttest: 0.6558264\tbest: 0.6558264 (100)\ttotal: 8.98s\tremaining: 14m 40s\n",
      "200:\tlearn: 0.6570170\ttest: 0.6624206\tbest: 0.6624206 (200)\ttotal: 17.9s\tremaining: 14m 32s\n",
      "300:\tlearn: 0.6647591\ttest: 0.6703989\tbest: 0.6704049 (299)\ttotal: 26.6s\tremaining: 14m 17s\n",
      "400:\tlearn: 0.6721103\ttest: 0.6789482\tbest: 0.6789849 (398)\ttotal: 35.1s\tremaining: 13m 59s\n",
      "500:\tlearn: 0.6783038\ttest: 0.6831809\tbest: 0.6832593 (499)\ttotal: 43.4s\tremaining: 13m 43s\n",
      "600:\tlearn: 0.6832657\ttest: 0.6860206\tbest: 0.6861332 (589)\ttotal: 51.7s\tremaining: 13m 29s\n",
      "700:\tlearn: 0.6880816\ttest: 0.6863476\tbest: 0.6864039 (698)\ttotal: 1m\tremaining: 13m 19s\n",
      "800:\tlearn: 0.6930657\ttest: 0.6866783\tbest: 0.6868923 (778)\ttotal: 1m 8s\tremaining: 13m 9s\n",
      "900:\tlearn: 0.6975270\ttest: 0.6870065\tbest: 0.6872307 (825)\ttotal: 1m 17s\tremaining: 12m 59s\n",
      "1000:\tlearn: 0.7021012\ttest: 0.6873978\tbest: 0.6876681 (994)\ttotal: 1m 25s\tremaining: 12m 48s\n",
      "1100:\tlearn: 0.7061001\ttest: 0.6872098\tbest: 0.6876681 (994)\ttotal: 1m 33s\tremaining: 12m 37s\n",
      "bestTest = 0.6876681337\n",
      "bestIteration = 994\n",
      "Shrink model to first 995 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6202125\ttest: 0.6200721\tbest: 0.6200721 (0)\ttotal: 91.3ms\tremaining: 15m 13s\n",
      "100:\tlearn: 0.6525028\ttest: 0.6529704\tbest: 0.6529704 (100)\ttotal: 8.96s\tremaining: 14m 38s\n",
      "200:\tlearn: 0.6587961\ttest: 0.6613840\tbest: 0.6613895 (198)\ttotal: 17.9s\tremaining: 14m 30s\n",
      "300:\tlearn: 0.6673138\ttest: 0.6712656\tbest: 0.6712656 (300)\ttotal: 26.5s\tremaining: 14m 13s\n",
      "400:\tlearn: 0.6741639\ttest: 0.6784103\tbest: 0.6784103 (400)\ttotal: 35s\tremaining: 13m 57s\n",
      "500:\tlearn: 0.6797240\ttest: 0.6823391\tbest: 0.6823391 (500)\ttotal: 43.3s\tremaining: 13m 41s\n",
      "600:\tlearn: 0.6849819\ttest: 0.6848060\tbest: 0.6848060 (600)\ttotal: 51.7s\tremaining: 13m 29s\n",
      "700:\tlearn: 0.6898141\ttest: 0.6849961\tbest: 0.6850335 (699)\ttotal: 1m\tremaining: 13m 18s\n",
      "800:\tlearn: 0.6945605\ttest: 0.6857412\tbest: 0.6859243 (780)\ttotal: 1m 8s\tremaining: 13m 8s\n",
      "900:\tlearn: 0.6990471\ttest: 0.6851299\tbest: 0.6859243 (780)\ttotal: 1m 17s\tremaining: 12m 59s\n",
      "bestTest = 0.6859243202\n",
      "bestIteration = 780\n",
      "Shrink model to first 781 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6219064\ttest: 0.6193612\tbest: 0.6193612 (0)\ttotal: 104ms\tremaining: 17m 24s\n",
      "100:\tlearn: 0.6516834\ttest: 0.6488412\tbest: 0.6488412 (100)\ttotal: 9.1s\tremaining: 14m 51s\n",
      "200:\tlearn: 0.6571535\ttest: 0.6548727\tbest: 0.6548727 (200)\ttotal: 18.1s\tremaining: 14m 42s\n",
      "300:\tlearn: 0.6663346\ttest: 0.6654799\tbest: 0.6656001 (295)\ttotal: 26.8s\tremaining: 14m 24s\n",
      "400:\tlearn: 0.6736356\ttest: 0.6721856\tbest: 0.6721856 (400)\ttotal: 35.4s\tremaining: 14m 7s\n",
      "500:\tlearn: 0.6797783\ttest: 0.6761932\tbest: 0.6762363 (499)\ttotal: 43.7s\tremaining: 13m 49s\n",
      "600:\tlearn: 0.6847814\ttest: 0.6788034\tbest: 0.6789287 (597)\ttotal: 52.1s\tremaining: 13m 35s\n",
      "700:\tlearn: 0.6898146\ttest: 0.6806312\tbest: 0.6806312 (700)\ttotal: 1m\tremaining: 13m 26s\n",
      "800:\tlearn: 0.6949283\ttest: 0.6810966\tbest: 0.6811519 (799)\ttotal: 1m 9s\tremaining: 13m 15s\n",
      "900:\tlearn: 0.6995097\ttest: 0.6811392\tbest: 0.6815054 (815)\ttotal: 1m 17s\tremaining: 13m 4s\n",
      "1000:\tlearn: 0.7036841\ttest: 0.6812412\tbest: 0.6817126 (939)\ttotal: 1m 25s\tremaining: 12m 52s\n",
      "1100:\tlearn: 0.7077045\ttest: 0.6814537\tbest: 0.6817126 (939)\ttotal: 1m 34s\tremaining: 12m 40s\n",
      "bestTest = 0.6817125534\n",
      "bestIteration = 939\n",
      "Shrink model to first 940 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.016489\n",
      "0:\tlearn: 0.6266670\ttest: 0.6247082\tbest: 0.6247082 (0)\ttotal: 97.3ms\tremaining: 16m 12s\n",
      "100:\tlearn: 0.6528941\ttest: 0.6489875\tbest: 0.6489875 (100)\ttotal: 9.02s\tremaining: 14m 44s\n",
      "200:\tlearn: 0.6593034\ttest: 0.6558013\tbest: 0.6560038 (193)\ttotal: 17.9s\tremaining: 14m 34s\n",
      "300:\tlearn: 0.6685413\ttest: 0.6672782\tbest: 0.6672782 (300)\ttotal: 26.6s\tremaining: 14m 16s\n",
      "400:\tlearn: 0.6755164\ttest: 0.6737909\tbest: 0.6737909 (400)\ttotal: 35.1s\tremaining: 14m 1s\n",
      "500:\tlearn: 0.6813258\ttest: 0.6780367\tbest: 0.6780811 (499)\ttotal: 43.5s\tremaining: 13m 44s\n",
      "600:\tlearn: 0.6863240\ttest: 0.6798501\tbest: 0.6798656 (592)\ttotal: 51.9s\tremaining: 13m 31s\n",
      "700:\tlearn: 0.6906659\ttest: 0.6805050\tbest: 0.6805050 (700)\ttotal: 1m\tremaining: 13m 19s\n",
      "800:\tlearn: 0.6957282\ttest: 0.6802605\tbest: 0.6808623 (707)\ttotal: 1m 8s\tremaining: 13m 8s\n",
      "900:\tlearn: 0.7000114\ttest: 0.6808966\tbest: 0.6808966 (900)\ttotal: 1m 17s\tremaining: 12m 57s\n",
      "1000:\tlearn: 0.7041056\ttest: 0.6806491\tbest: 0.6808966 (900)\ttotal: 1m 25s\tremaining: 12m 47s\n",
      "1100:\tlearn: 0.7078214\ttest: 0.6814000\tbest: 0.6815176 (1097)\ttotal: 1m 33s\tremaining: 12m 36s\n",
      "1200:\tlearn: 0.7112085\ttest: 0.6816554\tbest: 0.6818904 (1189)\ttotal: 1m 41s\tremaining: 12m 25s\n",
      "1300:\tlearn: 0.7143868\ttest: 0.6818655\tbest: 0.6819768 (1224)\ttotal: 1m 50s\tremaining: 12m 15s\n",
      "1400:\tlearn: 0.7174308\ttest: 0.6820862\tbest: 0.6822916 (1383)\ttotal: 1m 58s\tremaining: 12m 6s\n",
      "1500:\tlearn: 0.7207714\ttest: 0.6817073\tbest: 0.6822916 (1383)\ttotal: 2m 6s\tremaining: 11m 56s\n",
      "bestTest = 0.682291566\n",
      "bestIteration = 1383\n",
      "Shrink model to first 1384 iterations.\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "models = []\n",
    "\n",
    "\n",
    "models = []\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "\n",
    "    model = CatBoostClassifier(iterations=iterations,\n",
    "                               random_state=SEED,\n",
    "                               task_type=\"GPU\",\n",
    "                               eval_metric=\"F1\",\n",
    "                               cat_features=cat_features,\n",
    "                               one_hot_max_size=4,\n",
    "                               bagging_temperature=0.2,\n",
    "                               depth=10,\n",
    "# depth default 값을 모르겠지만 학습이 엄청 오래걸리게 된다.\n",
    "                               use_best_model=True)\n",
    "    model.fit(x_train.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            early_stopping_rounds=patience ,\n",
    "            verbose = 100\n",
    "        )\n",
    "    \n",
    "    models.append(model)\n",
    "    scores.append(model.get_best_score()[\"validation\"][\"F1\"])\n",
    "    if is_holdout:\n",
    "        break     # 0.6871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = preprocess_data(test_data, cols_equi)\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6886734849641276, 0.6876681337275069, 0.6859243202488102, 0.681712553433618, 0.6822915660322675]\n",
      "0.685254011681266\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "# hyperparemeter 수정 X\n",
    "# 결과 0.75 이전꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7184832593787818, 0.7151081897999327, 0.7119947362997139, 0.7136985421617108, 0.7150238765764664]\n",
      "threshold 0.38 mean 0.7148617208433211\n",
      "[0.7174931062052312, 0.714844634138455, 0.7120086548864045, 0.7134181983503279, 0.7147185825510448]\n",
      "threshold 0.39 mean 0.7144966352262927\n",
      "[0.7169063946723442, 0.7151116671982206, 0.711843523794856, 0.7127521412484178, 0.7140411959689069]\n",
      "threshold 0.4 mean 0.7141309845765491\n",
      "[0.7159854715484489, 0.7146972631997217, 0.7110334473677734, 0.7110486065457814, 0.7129343401070964]\n",
      "threshold 0.41 mean 0.7131398257537644\n",
      "[0.7147870352362188, 0.7125030379725619, 0.7099969255569312, 0.7098220682563363, 0.711525467219775]\n",
      "threshold 0.42 mean 0.7117269068483646\n",
      "max score :  0.7148617208433211\n",
      "fin_threshold :  0.38\n"
     ]
    }
   ],
   "source": [
    "max_score = 0 \n",
    "for threshold in [0.38, 0.39, 0.40, 0.41, 0.42,] :\n",
    "    pred_list = []\n",
    "    scores = []\n",
    "    for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "        pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "        pred = np.where(pred >= threshold , 1, 0)\n",
    "        score = f1_score(y_train[vai],pred)\n",
    "        scores.append(score)\n",
    "        pred = models[i].predict_proba(x_test)[:, 1]\n",
    "        pred_list.append(pred)\n",
    "    print(scores)\n",
    "    print('threshold', threshold, 'mean', np.mean(scores))\n",
    "    if np.mean(scores) > max_score : \n",
    "        max_score = np.mean(scores)\n",
    "        fin_threshold = threshold\n",
    "print(\"max score : \", max_score)\n",
    "print(\"fin_threshold : \", fin_threshold)\n",
    "\n",
    "# 최종모델 threshold 선정 후 다시 pred_list 만들기.\n",
    "for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "    pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "    pred = np.where(pred >= fin_threshold , 1, 0)\n",
    "    score = f1_score(y_train[vai],pred)\n",
    "    scores.append(score)\n",
    "    pred = models[i].predict_proba(x_test)[:, 1]\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hard voting 방법으로 변환한 앙상블\n",
    "\n",
    "count = [0] * len(pred_list[0])\n",
    "for i,pred in enumerate(pred_list) :\n",
    "    for  idx, data in enumerate(pred) :\n",
    "        if data >= threshold :\n",
    "            count[idx] += 1\n",
    "pred = np.where(np.array(count) >= 3, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 1 개수 :  33121\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission\n",
    "print('target 1 개수 : ',sum(sample_submission['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f\"{SUBMIT_PATH}catboost-made4-version2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 똑같은 것을 기존 산술평균 앙상블로 제출한다면?\n",
    "\n",
    "threshold = 0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7174931062052312, 0.714844634138455, 0.7120086548864045, 0.7134181983503279, 0.7147185825510448]\n",
      "0.7144966352262927\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "scores = []\n",
    "for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "    pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "    pred = np.where(pred >= threshold , 1, 0)\n",
    "    score = f1_score(y_train[vai],pred)\n",
    "    scores.append(score)\n",
    "    pred = models[i].predict_proba(x_test)[:, 1]\n",
    "    pred_list.append(pred)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.mean( pred_list , axis = 0 )\n",
    "pred = np.where(pred >= threshold , 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 1 개수 :  34371\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission\n",
    "print('target 1 개수 : ',sum(sample_submission['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f\"{SUBMIT_PATH}catboost-made4-version3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c97dde18f122f9d21c34c8255baf2515d19df3edbb55cbf82035c58b5acf6190"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
